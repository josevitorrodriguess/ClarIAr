![image](https://github.com/user-attachments/assets/815a6932-89bd-42b0-a0a5-32ef5da0cd48)
# ClarIAr Project
Project for Tril Lab's Hackathon

### Members:
- Miguel Queiroz
- Emyle Santos
- José Rodrigues
- Luís Aranha

![image](https://github.com/user-attachments/assets/0f9ab38d-a84f-4f4c-a49f-52dbc3cec14f)

## What is it about?

ClarIAr is a feature feature created to upgrade the functionality of TalkBack, improving the experience for visually impaired users in Android smartphones. 
It implements Artificial Inteligence to describe images on the screen with more accuracy and details.
In other words, ClarIAr is a acessibility resource created to enable blind people to use their phones in a more efficient way!

## How does it works?

### ClaIAr operates by:

  1. Capturing screen content in real-time;
  2. Processing images and interface elements through our AI model;
  3. Generating detailed, context-aware descriptions;
  4. Integrate the service with Talkback to ensure compatibility and a continuous accessibility experience;
  5. Delivering enhanced audio feedback to users.

![image](https://github.com/user-attachments/assets/63b0e9eb-703d-4319-9b22-488badbfef3a)
